{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48575c2d-4c29-40c8-af08-8b8596405de3",
   "metadata": {},
   "source": [
    "# AnyGPT for SELFIES-Data Modeling\n",
    "\n",
    "In this notebook, we find the best GPT architecture for SELFIES-data modeling via\n",
    "multiobjective hyperparameter optimization with `optuna` and autoregressive\n",
    "language modeling with `ü§ó transformers` and `‚ö°Ô∏è lightning`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa386d9a-95d4-42aa-8dd7-93e3d6d4bc1b",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "If you have already installed dependencies from our __environment.yml__, skip the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d980e4-6917-45e2-9286-9f75bcb1cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \\\n",
    "    torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu110 \\\n",
    "    pytorch-lightning transformers \\\n",
    "    optuna scikit-learn \\\n",
    "    rdkit-pypi selfies \\\n",
    "    pandas seaborn bertviz plotly \\\n",
    "    --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0057ef63-dc3d-4fc2-804d-f7ccafcfac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import gc\n",
    "import math\n",
    "import pathlib\n",
    "from typing import List, Literal, Optional, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import selfies as sf\n",
    "import torch\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "\n",
    "from tokenizers import Regex, Tokenizer\n",
    "from tokenizers.implementations import BaseTokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "from transformers import (DataCollatorForLanguageModeling,\n",
    "                          GPT2Config, GPT2LMHeadModel,\n",
    "                          PreTrainedTokenizerFast)\n",
    "\n",
    "from anygpt import AnyGPTConfig, AnyGPTForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab1a8d0-28c5-49a6-8e64-e0ffaf8624a3",
   "metadata": {},
   "source": [
    "Environment settings such as paths to data and logs, some hyperparameters, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9c8af0-996f-45fd-b9ae-5a38e074e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentConfig:\n",
    "    ROOT = pathlib.Path('..')\n",
    "    DATA_DIR = ROOT / 'data'\n",
    "    TRAIN_DATA = DATA_DIR / 'pubchem-10m-soft.sf'\n",
    "    LOG_DIR = ROOT / 'logs'\n",
    "    TOKENIZERS = LOG_DIR / 'tokenizers'\n",
    "    OPTIMIZE_HYPERPARAMS = False\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls):\n",
    "        cls.DATA_DIR.mkdir(exist_ok=True)\n",
    "        cls.LOG_DIR.mkdir(exist_ok=True)\n",
    "        cls.TOKENIZERS.mkdir(exist_ok=True)\n",
    "\n",
    "    @classmethod\n",
    "    def seed_everything(cls):\n",
    "        pl.seed_everything(1234, workers=True)\n",
    "\n",
    "    @classmethod\n",
    "    def set_seaborn_theme(cls):\n",
    "        sns.set_theme(context='paper', style='ticks', \n",
    "                      font='sans serif', font_scale=1.25)\n",
    "\n",
    "    @classmethod\n",
    "    def set_tokenizers_parallelism(cls, is_parallel='true'):\n",
    "        import os\n",
    "        os.environ['TOKENIZERS_PARALLELISM'] = is_parallel\n",
    "\n",
    "    @classmethod\n",
    "    def set_logging_levels(cls):\n",
    "        from rdkit.RDLogger import DisableLog\n",
    "\n",
    "        DisableLog('rdApp*')\n",
    "        optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "\n",
    "class MiniBatchConfig:\n",
    "    batch_size = 256\n",
    "    model_max_length = 128\n",
    "    workers = 36\n",
    "    gpus = 4\n",
    "    vocab_size = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12bcbaf-06f4-4e3e-8e86-41efe98fbd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    }
   ],
   "source": [
    "EnvironmentConfig.create_directories()\n",
    "EnvironmentConfig.seed_everything()\n",
    "EnvironmentConfig.set_seaborn_theme()\n",
    "EnvironmentConfig.set_tokenizers_parallelism(\"true\")\n",
    "EnvironmentConfig.set_logging_levels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab8063-21c1-4bbb-ad63-de119151e019",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Tokenization of SELFIES sequences and BPE segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72123e1-ef0c-4c7a-8189-54c2b7b8fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFTokenizer(BaseTokenizer):\n",
    "    Config = collections.namedtuple('Config',\n",
    "                                    ('pad, bos, eos, unk, eow, '\n",
    "                                     'pad_id, bos_id, eos_id, unk_id'))\n",
    "    config = Config('<pad>', '<bos>', '<eos>', '<unk>', '', *range(4))\n",
    "\n",
    "    def __init__(self, segmenation_model=None, **tokenizer_params):\n",
    "\n",
    "        segmenation_model = segmenation_model or BPE(\n",
    "            unk_token=self.config.unk, end_of_word_suffix=self.config.eow)\n",
    "        self._tokenizer = Tokenizer(segmenation_model)\n",
    "\n",
    "        pre_tokenizer_re = Regex('(\\]\\[|\\[|\\])')  # ][ or [ or ]\n",
    "        pre_tokenizer = Split(pre_tokenizer_re, 'removed')\n",
    "        self._tokenizer.pre_tokenizer = pre_tokenizer\n",
    "\n",
    "        post_processor = TemplateProcessing(\n",
    "            single=f'{self.config.bos} $A {self.config.eos}',\n",
    "            special_tokens=[(self.config.bos, self.config.bos_id),\n",
    "                            (self.config.eos, self.config.eos_id)],\n",
    "        )\n",
    "        self._tokenizer.post_processor = post_processor\n",
    "\n",
    "    @classmethod\n",
    "    def to_selfies(cls, smiles_sequence, **sf_kwargs):\n",
    "        return sf.encoder(smiles_sequence, **sf_kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_selfies(cls, selfies_sequence_n_spaces, **sf_kwargs):\n",
    "        selfies_tokens = selfies_sequence_n_spaces.split()\n",
    "        selfies_sequence = ''.join(\n",
    "            f'[{token}]' for token in selfies_tokens\n",
    "        )\n",
    "        return sf.decoder(selfies_sequence)\n",
    "        \n",
    "    def train(self, files,\n",
    "              vocab_size=MiniBatchConfig.vocab_size, min_frequency=10,\n",
    "              **bpe_kwargs):\n",
    "        bpe_trainer = BpeTrainer(\n",
    "            vocab_size=vocab_size,\n",
    "            min_frequency=min_frequency,\n",
    "            special_tokens=[self.config.pad, self.config.bos,\n",
    "                            self.config.eos, self.config.unk],\n",
    "            end_of_word_suffix=self.config.eow,\n",
    "            show_progress=False,\n",
    "            **bpe_kwargs,\n",
    "        )\n",
    "        self._tokenizer.train(files, trainer=bpe_trainer)\n",
    "\n",
    "    @classmethod\n",
    "    def get_pretrained(cls, *,\n",
    "                       tokenizer_object=None, tokenizer_file=None,\n",
    "                       model_max_length=MiniBatchConfig.model_max_length):\n",
    "        assert tokenizer_file is not None or tokenizer_object is not None\n",
    "\n",
    "        if tokenizer_object is not None:\n",
    "            pretrained_tokenizer = PreTrainedTokenizerFast(\n",
    "                tokenizer_object=tokenizer_object)\n",
    "        else:\n",
    "            pretrained_tokenizer = PreTrainedTokenizerFast(\n",
    "                tokenizer_file=str(tokenizer_file))\n",
    "\n",
    "        pretrained_tokenizer.add_special_tokens(dict(zip(\n",
    "            ['pad_token', 'bos_token', 'eos_token', 'unk_token'],\n",
    "            [cls.config.pad, cls.config.bos, cls.config.eos, cls.config.unk]\n",
    "        )))\n",
    "        pretrained_tokenizer.model_max_length = model_max_length\n",
    "        pretrained_tokenizer.to_selfies = cls.to_selfies\n",
    "        pretrained_tokenizer.from_selfies = cls.from_selfies\n",
    "\n",
    "        return pretrained_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd50eec-9ee6-4c9c-8028-83e3ba676750",
   "metadata": {},
   "source": [
    "Note: You can convert 10M SMILES Pubchem into SELFIES data using our\n",
    "__selfies-to-smiles.ipynb__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c9633d-a01f-4be4-92a4-7aa9a779dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "Tokens: ['<bos>', 'N', '=Branch1', 'C', '=O', 'C', '#N', '<eos>']\n",
      "CPU times: user 8.18 ms, sys: 2.46 ms, total: 10.6 ms\n",
      "Wall time: 2.82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer_file = EnvironmentConfig.TOKENIZERS / 'tokenizer.json'\n",
    "if not tokenizer_file.exists():\n",
    "    base_tokenizer = SFTokenizer()\n",
    "    base_tokenizer.train([str(EnvironmentConfig.TRAIN_DATA)])\n",
    "\n",
    "    print(f'Vocab size: {base_tokenizer.get_vocab_size()}')\n",
    "\n",
    "    base_tokenizer.save_model(str(EnvironmentConfig.TOKENIZERS))\n",
    "    base_tokenizer.save(str(tokenizer_file))\n",
    "\n",
    "    sample_smi = 'N(=O)C#N'\n",
    "    sample_sf = base_tokenizer.to_selfies(sample_smi)\n",
    "    encoded_sample_sf = base_tokenizer.encode(sample_sf)\n",
    "    print(f'Encoding type: {encoded_sample_sf!r}')\n",
    "    print(f'Tokens: {encoded_sample_sf.tokens}')\n",
    "    decoded_sample_sf = base_tokenizer.decode(encoded_sample_sf.ids)\n",
    "    assert sample_smi == base_tokenizer.from_selfies(decoded_sample_sf)\n",
    "\n",
    "    hf_tokenizer = base_tokenizer.get_pretrained(tokenizer_object=base_tokenizer)\n",
    "    assert base_tokenizer.get_vocab() == hf_tokenizer.vocab\n",
    "else:\n",
    "    hf_tokenizer = SFTokenizer.get_pretrained(tokenizer_file=tokenizer_file)\n",
    "\n",
    "    sample_smi = 'N(=O)C#N'\n",
    "    sample_sf = SFTokenizer.to_selfies(sample_smi)\n",
    "    encoded_sample_sf = hf_tokenizer(sample_sf)\n",
    "    print(f'Encoding keys: {encoded_sample_sf.keys()}')\n",
    "    print(f'Tokens: {encoded_sample_sf.tokens()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0584fd-5d2f-497d-992e-2ee92575be0e",
   "metadata": {},
   "source": [
    "SELFIES dataset, dataloader, and lightning datamodule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03ccf124-9c5e-4b99-ba6f-9a957ad3aab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 25, 60, 74, 15, 61, 15, 61, 15, 61, 65, 66, 15, 61, 15, 61, 15, 61,\n",
       "        65, 66, 15, 66, 15, 68, 25, 15, 15, 60, 15, 26, 15, 15, 26, 15, 15, 65,\n",
       "        71])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filename, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self._data = (\n",
    "            pathlib.Path(filename)\n",
    "            .read_text(encoding=\"ascii\")\n",
    "            .splitlines()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded_sf = self.tokenizer(\n",
    "            self._data[index], add_special_tokens=False,\n",
    "            truncation=True, return_tensors=\"pt\")\n",
    "        return encoded_sf[\"input_ids\"][0]\n",
    "\n",
    "\n",
    "dataset = SFDataset(EnvironmentConfig.TRAIN_DATA, hf_tokenizer)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "787d4e7b-c07b-41c3-a679-8d967f7a46b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'labels'])\n",
      "Input:\n",
      "tensor([[26, 61, 60,  ...,  0,  0,  0],\n",
      "        [15, 15, 15,  ...,  0,  0,  0],\n",
      "        [15, 26, 15,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [15, 15, 67,  ...,  0,  0,  0],\n",
      "        [15, 15, 67,  ...,  0,  0,  0],\n",
      "        [15, 26, 15,  ...,  0,  0,  0]])\n",
      "Output:\n",
      "tensor([[  26,   61,   60,  ..., -100, -100, -100],\n",
      "        [  15,   15,   15,  ..., -100, -100, -100],\n",
      "        [  15,   26,   15,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [  15,   15,   67,  ..., -100, -100, -100],\n",
      "        [  15,   15,   67,  ..., -100, -100, -100],\n",
      "        [  15,   26,   15,  ..., -100, -100, -100]])\n"
     ]
    }
   ],
   "source": [
    "collate_fn = DataCollatorForLanguageModeling(hf_tokenizer, mlm=False)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=MiniBatchConfig.batch_size,\n",
    "    shuffle=True, collate_fn=collate_fn, num_workers=MiniBatchConfig.workers)\n",
    "minibatch = next(iter(dataloader))\n",
    "print(minibatch.keys())\n",
    "print(f'Input:\\n{minibatch[\"input_ids\"]}')\n",
    "print(f'Output:\\n{minibatch[\"labels\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b846aff4-ff01-402c-8f8d-dc44070bf816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'labels']) 2 4750000\n",
      "tensor([[15, 25, 29, 66, 15, 68, 66, 15, 68, 15, 15, 25, 15, 66, 15, 68, 15, 61,\n",
      "         15, 61, 60, 65, 26, 15, 15, 61, 65, 67, 77,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [15, 15, 15, 61, 15, 61, 26, 15, 61, 15, 61, 15, 15, 15, 15, 15, 15, 15,\n",
      "         15, 66, 15, 68, 26, 15, 15, 67, 69, 26, 15, 26, 15, 26, 15, 67, 65, 66,\n",
      "         15, 26, 15, 26, 15, 60, 65, 15, 26, 15, 60, 15, 26, 15, 60, 15, 26, 15,\n",
      "         65, 75, 26, 15, 60, 15, 26, 15, 60, 15, 26, 15, 69, 65, 60, 26, 26, 15,\n",
      "         66, 15, 68, 15, 15, 15, 15, 15, 15, 15, 15, 61, 15, 15, 61, 15, 15, 61,\n",
      "         15, 15]])\n",
      "dict_keys(['input_ids', 'labels']) 2 250000\n",
      "tensor([[15, 15, 60, 74, 15, 61, 15, 61, 15, 61, 65, 66, 25, 15, 15, 61, 15, 61,\n",
      "         15, 61, 65, 66, 25, 15, 15, 65, 26, 68,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [26, 61, 60, 65, 25, 26, 15, 61, 15, 61, 67, 65, 61, 25, 67, 65, 15, 15,\n",
      "         61, 15, 61, 60, 67, 15, 70, 15, 61, 76, 65, 60, 15, 61, 65, 26, 15, 15,\n",
      "         15, 25, 15, 65, 60, 68, 15, 61, 69, 65, 67]])\n"
     ]
    }
   ],
   "source": [
    "class SFDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename: str,\n",
    "        tokenizer: PreTrainedTokenizerFast,\n",
    "        batch_size: int = MiniBatchConfig.batch_size,\n",
    "        num_workers: int = MiniBatchConfig.workers,\n",
    "        train_size: float = 0.95,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self._filename = filename\n",
    "        self._tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_size = train_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dataset = SFDataset(self._filename, self._tokenizer)\n",
    "        self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n",
    "            dataset,\n",
    "            [int(self.train_size * len(dataset)),\n",
    "             int((1 - self.train_size) * len(dataset))],\n",
    "            generator=torch.Generator().manual_seed(1234),\n",
    "        )\n",
    "        self.collate_fn = DataCollatorForLanguageModeling(self._tokenizer,\n",
    "                                                          mlm=False)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "            collate_fn=self.collate_fn, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "            collate_fn=self.collate_fn, num_workers=self.num_workers)\n",
    "\n",
    "\n",
    "del dataloader, collate_fn, dataset\n",
    "gc.collect()\n",
    "\n",
    "datamodule = SFDataModule(EnvironmentConfig.TRAIN_DATA, hf_tokenizer,\n",
    "                          batch_size=2, num_workers=0)\n",
    "datamodule.setup()\n",
    "for dataloader in datamodule.train_dataloader(), datamodule.val_dataloader():\n",
    "    minibatch = next(iter(dataloader))\n",
    "    print(minibatch.keys(), len(minibatch), len(dataloader))\n",
    "    print(minibatch[\"input_ids\"])\n",
    "\n",
    "del dataloader, datamodule, minibatch\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b58a1-57f9-4af2-817c-8eee319134e0",
   "metadata": {},
   "source": [
    "Utilities to generate and validate new SELFIES sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d3ede80-7875-4aa8-8500-e4d6941c7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(\n",
    "    generated_sf_list: List[str],\n",
    "    tokenizer: PreTrainedTokenizerFast,\n",
    ") -> bool:\n",
    "    try:\n",
    "        generated_sf_str = tokenizer.from_selfies(generated_sf_list)\n",
    "        smi = MolFromSmiles(generated_sf_str)\n",
    "        return True\n",
    "    except (sf.DecoderError, TypeError):\n",
    "        return False\n",
    "\n",
    "\n",
    "def generate(\n",
    "    model: \"AnyGPTLitModelForCausalLM\",\n",
    "    tokenizer: PreTrainedTokenizerFast,\n",
    "    top_p: float = 0.95,\n",
    "    repetition_penalty: float = 1.2,\n",
    ") -> str:\n",
    "    model.eval()\n",
    "\n",
    "    selfies_start = torch.tensor([[tokenizer.bos_token_id]], device=model.device)\n",
    "    generated_ids = model.generate(\n",
    "        selfies_start,\n",
    "        max_length=tokenizer.model_max_length,\n",
    "        do_sample=True,\n",
    "        top_p=top_p,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    generated_tokens = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ed638a-f7cc-40fe-96a5-507072ebd196",
   "metadata": {},
   "source": [
    "## AnyGPT\n",
    "\n",
    "Lightning wrapper for _AnyGPT_ $-$ general architecture of GPT for 1D molecular modeling.\n",
    "See **anygpt.py** module for implementation details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c4c87c-d885-4028-905c-613275c79172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['loss', 'logits', 'past_key_values'])\n"
     ]
    }
   ],
   "source": [
    "class AnyGPTLitModelForCausalLM(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, tokenizer, *,\n",
    "\n",
    "        # AnyGPTConfig (hyper)parameters:\n",
    "        #     Embeddings\n",
    "        vocab_size: int = 240,\n",
    "        max_position_embeddings: int = MiniBatchConfig.model_max_length,\n",
    "        add_positional_encoding: bool = True,\n",
    "        #     Number and type of layers\n",
    "        num_layers: int = 6,\n",
    "        architecture_scheme: Tuple[Literal[\"a\", \"m\", \"b\"]] = tuple(\"abbbbm\"),\n",
    "        #     Attention type\n",
    "        attention_type: Literal[\"global\", \"local\"] = \"local\",\n",
    "        window_size: Optional[int] = 96,\n",
    "        #     Projections\n",
    "        num_heads: int = 12,\n",
    "        hidden_size: int = 32 * 12,\n",
    "        intermediate_size: Optional[int] = (32 * 12) * 3,\n",
    "        activation_function: Literal[\"gelu_new\", \"silu\", \"relu\"] = \"gelu_new\",\n",
    "        #     All three dropouts\n",
    "        dropout: float = 0.1,\n",
    "        #     Layer normalization\n",
    "        layer_norm_position: Literal[\"pre-ln\", \"post-ln\", \"none\"] = \"pre-ln\",\n",
    "        layer_norm_epsilon: float = 1e-5,\n",
    "\n",
    "        # *Adam* hyperparameters\n",
    "        lr: float = 5e-4,\n",
    "        wd: float = 0.0,\n",
    "        adam_eps: float = 1e-7,\n",
    "        adam_betas: float = (0.93, 0.995), \n",
    "\n",
    "        # Cosine scheduler hyperparameters\n",
    "        scheduler_T_max: int = 130_000,\n",
    "        scheduler_eta_min: float = 1e-8,\n",
    "        scheduler_frequency: int = 1,\n",
    "\n",
    "        # Validation\n",
    "        num_generate: int = 500,\n",
    "        top_p: float = 0.9,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=(\"tokenizer\",))\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        model_config = AnyGPTConfig(\n",
    "            vocab_size=vocab_size,\n",
    "            max_position_embeddings=max_position_embeddings,\n",
    "            add_positional_encoding=add_positional_encoding,\n",
    "            num_layers=num_layers,\n",
    "            architecture_scheme=architecture_scheme,\n",
    "            attention_type=attention_type,\n",
    "            window_size=window_size,\n",
    "            num_heads=num_heads,\n",
    "            hidden_size=hidden_size,\n",
    "            intermediate_size=intermediate_size,\n",
    "            activation_function=activation_function,\n",
    "            embed_dropout=dropout,\n",
    "            attention_dropout=dropout,\n",
    "            resid_dropout=dropout,\n",
    "            layer_norm_position=layer_norm_position,\n",
    "            layer_norm_epsilon=layer_norm_epsilon,\n",
    "        )\n",
    "        self.model = AnyGPTForCausalLM(model_config)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "\n",
    "        loss = outputs['loss']\n",
    "        ppl = torch.exp(loss)\n",
    "        performance = {'loss': loss, 'ppl': ppl}\n",
    "\n",
    "        self.log('loss', performance['loss'],\n",
    "                 on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "        self.log('train_ppl', performance['ppl'],\n",
    "                 on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "\n",
    "        return performance\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "\n",
    "        val_ppl = torch.exp(outputs[\"loss\"])\n",
    "\n",
    "        self.log(\"val_ppl\", val_ppl,\n",
    "                 on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "\n",
    "        return val_ppl\n",
    "\n",
    "    def validation_epoch_end(self, steps):\n",
    "        mean_ppl = torch.stack(steps).mean()\n",
    "\n",
    "        # TODO: something is unpicklable in this notebook\n",
    "        # generated = joblib.Parallel(n_jobs=-1)(\n",
    "        #     joblib.delayed(generate)(self.model, self.tokenizer, self.hparams.top_p)\n",
    "        #     for _ in range(self.hparams.num_generate)\n",
    "        # )\n",
    "        generated = [\n",
    "            generate(self.model, self.tokenizer, self.hparams.top_p)\n",
    "            for _ in range(self.hparams.num_generate)\n",
    "        ]\n",
    "        uniq_generated = frozenset(generated)\n",
    "        validity = sum(map(functools.partial(is_valid, tokenizer=self.tokenizer),\n",
    "                           uniq_generated))\n",
    "        rac = validity / self.hparams.num_generate\n",
    "\n",
    "        self.log(\"rac\", rac,\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_ppl\", mean_ppl,\n",
    "                 on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.wd,\n",
    "            eps=self.hparams.adam_eps,\n",
    "            betas=self.hparams.adam_betas,\n",
    "        )\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            eta_min=self.hparams.scheduler_eta_min,\n",
    "            T_max=self.hparams.scheduler_T_max,\n",
    "        )\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler,\n",
    "                'interval': 'step',\n",
    "                'frequency': self.hparams.scheduler_frequency,\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "datamodule = SFDataModule(EnvironmentConfig.TRAIN_DATA, hf_tokenizer)\n",
    "datamodule.setup()\n",
    "minibatch = next(iter(datamodule.train_dataloader()))\n",
    "\n",
    "hf_model = AnyGPTForCausalLM(AnyGPTConfig())\n",
    "model_outputs = hf_model(**minibatch)\n",
    "print(model_outputs.keys())\n",
    "\n",
    "del datamodule, minibatch, hf_model, model_outputs\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd448b1-cf1a-4c26-925a-0641bb5a7ee5",
   "metadata": {},
   "source": [
    "Architecture search based on multiobjective hyperparameter optimization.\n",
    "Objectives are _ration of accepted molecules_ and _perplexity_.\n",
    "Hyperparameters include _sandwich coefficient_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad78bb6-f126-43ca-a6cb-76f8c72e15fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optuna_objective(trial):\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 6, 8)\n",
    "    sandwich_coef = trial.suggest_int(\"sandwich_coef\", 0, num_layers // 2)\n",
    "    architecture_scheme = (\n",
    "        \"a\" * sandwich_coef\n",
    "        + \"b\" * (num_layers - 2 * sandwich_coef)\n",
    "        + \"m\" * sandwich_coef\n",
    "    )\n",
    "\n",
    "    add_positional_encoding = trial.suggest_categorical(\"add_pos_enc\", [True, False])\n",
    "\n",
    "    attention_type = trial.suggest_categorical(\"attn_type\", [\"global\", \"local\"])\n",
    "    if attention_type == \"local\":\n",
    "        window_size = trial.suggest_int(\"window_size\",\n",
    "                                        64, MiniBatchConfig.model_max_length, 8)\n",
    "    else:\n",
    "        window_size = None\n",
    "\n",
    "    num_heads = trial.suggest_int(\"num_heads\", 9, 12)\n",
    "    hidden_size = num_heads * trial.suggest_categorical(\"h_per_head\", (24, 32, 48))\n",
    "    intermediate_size = hidden_size * trial.suggest_int(\"h_mlp_mult\", 2, 4)\n",
    "\n",
    "    activation_function = trial.suggest_categorical(\"act_fn\",\n",
    "                                                    [\"gelu_new\", \"silu\", \"relu\"])\n",
    "\n",
    "    dropout = trial.suggest_uniform(\"drop\", 0.05, 0.15)\n",
    "\n",
    "    layer_norm_position = trial.suggest_categorical(\"ln_pos\",\n",
    "                                                    [\"pre-ln\", \"post-ln\", \"none\"])\n",
    "\n",
    "    top_p = trial.suggest_uniform(\"top_p\", 0.85, 0.95)\n",
    "\n",
    "    early_stopping_rac = pl.callbacks.early_stopping.EarlyStopping(\n",
    "        monitor=\"rac\",\n",
    "        patience=3,\n",
    "        min_delta=2e-2,\n",
    "        check_finite=False,\n",
    "        stopping_threshold=1.0,\n",
    "        divergence_threshold=None,\n",
    "        verbose=False,\n",
    "        mode=\"max\",\n",
    "        check_on_train_epoch_end=True,\n",
    "    )\n",
    "    early_stopping_val_ppl = pl.callbacks.early_stopping.EarlyStopping(\n",
    "        monitor=\"val_ppl\",\n",
    "        patience=2,\n",
    "        min_delta=1e-2,\n",
    "        check_finite=True,\n",
    "        stopping_threshold=1.98,\n",
    "        divergence_threshold=3.5,\n",
    "        verbose=False,\n",
    "        mode=\"min\",\n",
    "        check_on_train_epoch_end=True,\n",
    "    )\n",
    "    lit_model_trainer = pl.Trainer(\n",
    "        logger=False,\n",
    "        enable_checkpointing=False,\n",
    "        strategy=\"dp\",\n",
    "        callbacks=[early_stopping_rac, early_stopping_val_ppl],\n",
    "        gpus=MiniBatchConfig.gpus,\n",
    "        min_epochs=3,\n",
    "        max_epochs=16,\n",
    "        limit_train_batches=0.15,\n",
    "    )\n",
    "    datamodule = SFDataModule(\n",
    "        EnvironmentConfig.TRAIN_DATA,\n",
    "        hf_tokenizer,\n",
    "        batch_size=MiniBatchConfig.batch_size,\n",
    "        num_workers=MiniBatchConfig.workers,\n",
    "    )\n",
    "    lit_model = AnyGPTLitModelForCausalLM(\n",
    "        # Fixed hyperparameters\n",
    "        hf_tokenizer,\n",
    "        vocab_size=hf_tokenizer.vocab_size,\n",
    "        max_position_embeddings=MiniBatchConfig.model_max_length,\n",
    "        # Tunable hyperparameters\n",
    "        num_layers=num_layers,\n",
    "        architecture_scheme=tuple(architecture_scheme),\n",
    "        add_positional_encoding=add_positional_encoding,\n",
    "        attention_type=attention_type,\n",
    "        window_size=window_size,\n",
    "        num_heads=num_heads,\n",
    "        hidden_size=hidden_size,\n",
    "        intermediate_size=intermediate_size,\n",
    "        activation_function=activation_function,\n",
    "        dropout=dropout,\n",
    "        layer_norm_position=layer_norm_position,\n",
    "        top_p=top_p,\n",
    "        # Handcrafted hyperparameters\n",
    "        layer_norm_epsilon=3e-6,\n",
    "        adam_betas=(0.93, 0.994),\n",
    "        adam_eps=2e-7,\n",
    "        wd=0.0,\n",
    "        scheduler_T_max=75_000,\n",
    "        scheduler_eta_min=1e-8,\n",
    "        scheduler_frequency=1,\n",
    "    )\n",
    "    lit_model_trainer.fit(lit_model, datamodule=datamodule)\n",
    "\n",
    "    metrics = lit_model_trainer.callback_metrics\n",
    "    return metrics[\"val_ppl\"].item(), metrics[\"rac\"].item()\n",
    "\n",
    "\n",
    "if EnvironmentConfig.OPTIMIZE_HYPERPARAMS:\n",
    "    study_name = \"anygpt-multiobj\"\n",
    "    storage_name = f\"sqlite:///{study_name}-optuna.db\"\n",
    "    pkl_name = f\"{study_name}-optuna.pkl\"\n",
    "\n",
    "    optuna_study = optuna.create_study(\n",
    "        directions=[\"minimize\", \"maximize\"],\n",
    "        load_if_exists=True, study_name=study_name, storage=storage_name)\n",
    "    optuna_study.optimize(create_optuna_objective, n_trials=40)\n",
    "\n",
    "    joblib.dump(optuna_study, pkl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff4873b-44ba-48d6-9342-a2af4a0d850e",
   "metadata": {},
   "source": [
    "Pretraining the best GPT on 10M SELFIES data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a9fb6-d229-45b1-b9b7-58698c65cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "EnvironmentConfig.set_tokenizers_parallelism(\"false\")\n",
    "\n",
    "csv_logger = pl.loggers.CSVLogger(\n",
    "    EnvironmentConfig.LOG_DIR,\n",
    "    flush_logs_every_n_steps=200,\n",
    ")\n",
    "checkpoint_cb = pl.callbacks.ModelCheckpoint(csv_logger.log_dir)\n",
    "early_stopping_val_ppl = pl.callbacks.early_stopping.EarlyStopping(\n",
    "    monitor=\"val_ppl\",\n",
    "    patience=4,\n",
    "    min_delta=5e-3,\n",
    "    check_finite=True,\n",
    "    stopping_threshold=None,\n",
    "    divergence_threshold=3.0,\n",
    "    verbose=True,\n",
    "    mode=\"min\",\n",
    "    check_on_train_epoch_end=True,\n",
    ")\n",
    "\n",
    "lit_model_trainer = pl.Trainer(\n",
    "    logger=csv_logger,\n",
    "    callbacks=[checkpoint_cb, early_stopping_val_ppl],\n",
    "    strategy=\"dp\",\n",
    "    gpus=MiniBatchConfig.gpus,\n",
    "    max_epochs=30,\n",
    "    min_epochs=10,\n",
    "    val_check_interval=0.4,\n",
    "    limit_train_batches=0.2,\n",
    "    log_every_n_steps=200,\n",
    "    auto_scale_batch_size=False,\n",
    "    auto_lr_find=False,\n",
    ")\n",
    "datamodule = SFDataModule(EnvironmentConfig.TRAIN_DATA, hf_tokenizer,\n",
    "                          batch_size=MiniBatchConfig.batch_size,\n",
    "                          num_workers=MiniBatchConfig.workers)\n",
    "lit_model = AnyGPTLitModelForCausalLM(\n",
    "    hf_tokenizer,\n",
    "    vocab_size=MiniBatchConfig.vocab_size,\n",
    "    max_position_embeddings=MiniBatchConfig.model_max_length,\n",
    "    add_positional_encoding=True,\n",
    "    num_layers=7,\n",
    "    architecture_scheme=tuple(\"aaabmmm\"),\n",
    "    attention_type=\"global\",\n",
    "    window_size=None,\n",
    "    num_heads=11,\n",
    "    hidden_size=48 * 11,\n",
    "    intermediate_size=(48 * 11) * 4,\n",
    "    activation_function=\"gelu_new\",\n",
    "    dropout=0.1,\n",
    "    layer_norm_position=\"none\",\n",
    "    layer_norm_epsilon=1e-5,\n",
    "    lr=5e-4,\n",
    "    wd=0.0,\n",
    "    adam_eps=1e-7,\n",
    "    adam_betas=(0.93, 0.995),\n",
    "    scheduler_T_max=150_000,\n",
    "    scheduler_eta_min=1e-8,\n",
    "    scheduler_frequency=1,\n",
    "    top_p=0.94,\n",
    ")\n",
    "lit_model_trainer.fit(lit_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88ca9817-d6c5-40df-a5b9-d8d0fdfdd951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bfb16_row0_col0, #T_bfb16_row0_col3, #T_bfb16_row1_col3, #T_bfb16_row2_col3, #T_bfb16_row3_col1, #T_bfb16_row3_col2, #T_bfb16_row3_col3, #T_bfb16_row4_col3, #T_bfb16_row5_col3, #T_bfb16_row6_col3, #T_bfb16_row7_col3, #T_bfb16_row8_col3, #T_bfb16_row9_col3 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row0_col1, #T_bfb16_row0_col2 {\n",
       "  background-color: #f8f1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row1_col0 {\n",
       "  background-color: #eee9f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row1_col1 {\n",
       "  background-color: #a2bcda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row1_col2 {\n",
       "  background-color: #a7bddb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row2_col0 {\n",
       "  background-color: #d7d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row2_col1, #T_bfb16_row2_col2, #T_bfb16_row9_col0 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row3_col0 {\n",
       "  background-color: #b4c4df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row4_col0 {\n",
       "  background-color: #8bb2d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row4_col1 {\n",
       "  background-color: #76aad0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row4_col2 {\n",
       "  background-color: #7bacd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row5_col0 {\n",
       "  background-color: #589ec8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row5_col1, #T_bfb16_row6_col1 {\n",
       "  background-color: #3d93c2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row5_col2 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row6_col0 {\n",
       "  background-color: #2685bb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row6_col2 {\n",
       "  background-color: #4295c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row7_col0 {\n",
       "  background-color: #056ba7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row7_col1 {\n",
       "  background-color: #a8bedc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row7_col2 {\n",
       "  background-color: #acc0dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row8_col0 {\n",
       "  background-color: #045687;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row8_col1 {\n",
       "  background-color: #4897c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row8_col2 {\n",
       "  background-color: #4e9ac6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfb16_row9_col1 {\n",
       "  background-color: #f1ebf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfb16_row9_col2 {\n",
       "  background-color: #f1ebf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bfb16\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bfb16_level0_col0\" class=\"col_heading level0 col0\" >step</th>\n",
       "      <th id=\"T_bfb16_level0_col1\" class=\"col_heading level0 col1\" >cross-entropy</th>\n",
       "      <th id=\"T_bfb16_level0_col2\" class=\"col_heading level0 col2\" >perplexity</th>\n",
       "      <th id=\"T_bfb16_level0_col3\" class=\"col_heading level0 col3\" >epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row0\" class=\"row_heading level0 row0\" >84871</th>\n",
       "      <td id=\"T_bfb16_row0_col0\" class=\"data row0 col0\" >161399</td>\n",
       "      <td id=\"T_bfb16_row0_col1\" class=\"data row0 col1\" >0.639978</td>\n",
       "      <td id=\"T_bfb16_row0_col2\" class=\"data row0 col2\" >1.896440</td>\n",
       "      <td id=\"T_bfb16_row0_col3\" class=\"data row0 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row1\" class=\"row_heading level0 row1\" >84872</th>\n",
       "      <td id=\"T_bfb16_row1_col0\" class=\"data row1 col0\" >161599</td>\n",
       "      <td id=\"T_bfb16_row1_col1\" class=\"data row1 col1\" >0.673612</td>\n",
       "      <td id=\"T_bfb16_row1_col2\" class=\"data row1 col2\" >1.961309</td>\n",
       "      <td id=\"T_bfb16_row1_col3\" class=\"data row1 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row2\" class=\"row_heading level0 row2\" >86828</th>\n",
       "      <td id=\"T_bfb16_row2_col0\" class=\"data row2 col0\" >161799</td>\n",
       "      <td id=\"T_bfb16_row2_col1\" class=\"data row2 col1\" >0.735433</td>\n",
       "      <td id=\"T_bfb16_row2_col2\" class=\"data row2 col2\" >2.086386</td>\n",
       "      <td id=\"T_bfb16_row2_col3\" class=\"data row2 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row3\" class=\"row_heading level0 row3\" >86829</th>\n",
       "      <td id=\"T_bfb16_row3_col0\" class=\"data row3 col0\" >161999</td>\n",
       "      <td id=\"T_bfb16_row3_col1\" class=\"data row3 col1\" >0.635041</td>\n",
       "      <td id=\"T_bfb16_row3_col2\" class=\"data row3 col2\" >1.887099</td>\n",
       "      <td id=\"T_bfb16_row3_col3\" class=\"data row3 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row4\" class=\"row_heading level0 row4\" >86830</th>\n",
       "      <td id=\"T_bfb16_row4_col0\" class=\"data row4 col0\" >162199</td>\n",
       "      <td id=\"T_bfb16_row4_col1\" class=\"data row4 col1\" >0.684547</td>\n",
       "      <td id=\"T_bfb16_row4_col2\" class=\"data row4 col2\" >1.982873</td>\n",
       "      <td id=\"T_bfb16_row4_col3\" class=\"data row4 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row5\" class=\"row_heading level0 row5\" >86831</th>\n",
       "      <td id=\"T_bfb16_row5_col0\" class=\"data row5 col0\" >162399</td>\n",
       "      <td id=\"T_bfb16_row5_col1\" class=\"data row5 col1\" >0.696220</td>\n",
       "      <td id=\"T_bfb16_row5_col2\" class=\"data row5 col2\" >2.006155</td>\n",
       "      <td id=\"T_bfb16_row5_col3\" class=\"data row5 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row6\" class=\"row_heading level0 row6\" >86832</th>\n",
       "      <td id=\"T_bfb16_row6_col0\" class=\"data row6 col0\" >162599</td>\n",
       "      <td id=\"T_bfb16_row6_col1\" class=\"data row6 col1\" >0.696401</td>\n",
       "      <td id=\"T_bfb16_row6_col2\" class=\"data row6 col2\" >2.006518</td>\n",
       "      <td id=\"T_bfb16_row6_col3\" class=\"data row6 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row7\" class=\"row_heading level0 row7\" >86833</th>\n",
       "      <td id=\"T_bfb16_row7_col0\" class=\"data row7 col0\" >162799</td>\n",
       "      <td id=\"T_bfb16_row7_col1\" class=\"data row7 col1\" >0.672197</td>\n",
       "      <td id=\"T_bfb16_row7_col2\" class=\"data row7 col2\" >1.958535</td>\n",
       "      <td id=\"T_bfb16_row7_col3\" class=\"data row7 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row8\" class=\"row_heading level0 row8\" >86834</th>\n",
       "      <td id=\"T_bfb16_row8_col0\" class=\"data row8 col0\" >162999</td>\n",
       "      <td id=\"T_bfb16_row8_col1\" class=\"data row8 col1\" >0.694067</td>\n",
       "      <td id=\"T_bfb16_row8_col2\" class=\"data row8 col2\" >2.001841</td>\n",
       "      <td id=\"T_bfb16_row8_col3\" class=\"data row8 col3\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfb16_level0_row9\" class=\"row_heading level0 row9\" >86835</th>\n",
       "      <td id=\"T_bfb16_row9_col0\" class=\"data row9 col0\" >163199</td>\n",
       "      <td id=\"T_bfb16_row9_col1\" class=\"data row9 col1\" >0.644618</td>\n",
       "      <td id=\"T_bfb16_row9_col2\" class=\"data row9 col2\" >1.905260</td>\n",
       "      <td id=\"T_bfb16_row9_col3\" class=\"data row9 col3\" >21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fcb1ced65b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir = pathlib.Path(csv_logger.log_dir)\n",
    "metric_logs = pd.read_csv(log_dir / \"metrics.csv\")\n",
    "metric_logs = (\n",
    "    metric_logs\n",
    "    .rename({\"loss\": \"cross-entropy\", \"train_ppl\": \"perplexity\"}, axis=1)\n",
    "    .dropna(subset=\"perplexity\")\n",
    "    [[\"step\", \"cross-entropy\", \"perplexity\", \"epoch\"]]\n",
    "    .astype({\"epoch\": int})\n",
    ")\n",
    "metric_logs.tail(10).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4694a239-dc1b-4761-9feb-886eb92d890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.lineplot(x='step', y='value', hue='variable',\n",
    "                 data=pd.melt(metric_logs.drop(columns='epoch'), ['step']))\n",
    "g.set_xticks((metric_logs.step.min(), metric_logs.step.max()),\n",
    "             (metric_logs.epoch.min().astype(int), metric_logs.epoch.max().astype(int)))\n",
    "g.set_xlabel('epoch')\n",
    "g.set_ylabel('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(log_dir / \"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a653b72-7559-43f8-8344-eb96e0f9dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.model.config.save_pretrained(log_dir)\n",
    "lit_model.model.save_pretrained(log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
